{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了能用深度学习来解决现实世界的问题，我们经常从预处理原始数据开始， 而不是从那些准备好的张量格式数据开始。 在Python中常用的数据分析工具中，我们通常使用pandas软件包。 像庞大的Python生态系统中的许多其他扩展包一样，pandas可以与张量兼容。 本节我们将简要介绍使用pandas预处理原始数据，并将原始数据转换为张量格式的步骤。 后面的章节将介绍更多的数据预处理技术。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2.2.1 读取数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举一个例子，我们首先创建一个人工数据集，并存储在CSV（逗号分隔值）文件 ../data/house_tiny.csv中。 以其他格式存储的数据也可以通过类似的方式进行处理。 下面我们将数据集按行写入CSV文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('.', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('.', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')  # 列名\n",
    "    f.write('NA,Pave,127500\\n')  # 每行表示一个数据样本\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要从创建的CSV文件中加载原始数据集，我们导入pandas包并调用read_csv函数。该数据集有四行三列。其中每行描述了房间数量（“NumRooms”）、巷子类型（“Alley”）和房屋价格（“Price”）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 处理缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，“NaN”项代表缺失值。 为了处理缺失的数据，典型的方法包括插值法和删除法， 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值。 在这里，我们将考虑插值法。\n",
    "\n",
    "通过位置索引iloc，我们将data分成inputs和outputs， 其中前者为data的前两列，而后者为data的最后一列。 对于inputs中缺少的数值，我们用同一列的均值替换“NaN”项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2-1-data-preparation.ipynb 2.2.2 处理缺失值\\n\\n```python\\ninputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\\ninputs = inputs.fillna(inputs.mean())\\nprint(inputs)\\n```\\nhttps://github.com/d2l-ai/d2l-zh/pull/1331\\n    由于旧版Pandas库在对inputs执行mean()方法时，会跳过不可计算的类型，从而忽略报错直接计算出数据；\\n    而高版本pandas库会对数据类型进行严格检查，从而触发报错：\\n    “TypeError: can only concatenate str (not \"int\") to str”\\n\\n---------------------------------------------------------------------------\\nTypeError                                 Traceback (most recent call last)\\nCell In[4], line 2\\n      1 inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\\n----> 2 inputs = inputs.fillna(inputs.mean())\\n      3 print(inputs)\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\\\pandas\\\\core\\x0crame.py:11693, in DataFrame.mean(self, axis, skipna, numeric_only, **kwargs)\\n  11685 @doc(make_doc(\"mean\", ndim=2))\\n  11686 def mean(\\n  11687     self,\\n   (...)\\n  11691     **kwargs,\\n  11692 ):\\n> 11693     result = super().mean(axis, skipna, numeric_only, **kwargs)\\n  11694     if isinstance(result, Series):\\n  11695         result = result.__finalize__(self, method=\"mean\")\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py:12420, in NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\\n  12413 def mean(\\n  12414     self,\\n  12415     axis: Axis | None = 0,\\n   (...)\\n  12418     **kwargs,\\n  12419 ) -> Series | float:\\n> 12420     return self._stat_function(\\n  12421         \"mean\", nanops.nanmean, axis, skipna, numeric_only, **kwargs\\n  12422     )\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py:12377, in NDFrame._stat_function(self, name, func, axis, skipna, numeric_only, **kwargs)\\n  12373 nv.validate_func(name, (), kwargs)\\n  12375 validate_bool_kwarg(skipna, \"skipna\", none_allowed=False)\\n> 12377 return self._reduce(\\n  12378     func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only\\n  12379 )\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\\\pandas\\\\core\\x0crame.py:11562, in DataFrame._reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\\n  11558     df = df.T\\n  11560 # After possibly _get_data and transposing, we are now in the\\n  11561 #  simple case where we can use BlockManager.reduce\\n> 11562 res = df._mgr.reduce(blk_func)\\n  11563 out = df._constructor_from_mgr(res, axes=res.axes).iloc[0]\\n  11564 if out_dtype is not None and out.dtype != \"boolean\":\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\internals\\\\managers.py:1500, in BlockManager.reduce(self, func)\\n   1498 res_blocks: list[Block] = []\\n   1499 for blk in self.blocks:\\n-> 1500     nbs = blk.reduce(func)\\n   1501     res_blocks.extend(nbs)\\n   1503 index = Index([None])  # placeholder\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\internals\\x08locks.py:404, in Block.reduce(self, func)\\n    398 @final\\n    399 def reduce(self, func) -> list[Block]:\\n    400     # We will apply the function and reshape the result into a single-row\\n    401     #  Block with the same mgr_locs; squeezing will be done at a higher level\\n    402     assert self.ndim == 2\\n--> 404     result = func(self.values)\\n    406     if self.values.ndim == 1:\\n    407         res_values = result\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\\\pandas\\\\core\\x0crame.py:11481, in DataFrame._reduce.<locals>.blk_func(values, axis)\\n  11479         return np.array([result])\\n  11480 else:\\n> 11481     return op(values, axis=axis, skipna=skipna, **kwds)\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\\\pandas\\\\core\\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds)\\n    145         result = alt(values, axis=axis, skipna=skipna, **kwds)\\n    146 else:\\n--> 147     result = alt(values, axis=axis, skipna=skipna, **kwds)\\n    149 return result\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\\\pandas\\\\core\\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs)\\n    401 if datetimelike and mask is None:\\n    402     mask = isna(values)\\n--> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\\n    406 if datetimelike:\\n    407     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\\\pandas\\\\core\\nanops.py:719, in nanmean(values, axis, skipna, mask)\\n    716     dtype_count = dtype\\n    718 count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\\n--> 719 the_sum = values.sum(axis, dtype=dtype_sum)\\n    720 the_sum = _ensure_numeric(the_sum)\\n    722 if axis is not None and getattr(the_sum, \"ndim\", False):\\n\\nFile d:\\\\edison\\x07naconda3\\\\envs\\test\\\\lib\\\\site-packages\\numpy\\\\core\\\\_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where)\\n     47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\\n     48          initial=_NoValue, where=True):\\n---> 49     return umr_sum(a, axis, dtype, out, keepdims, initial, where)\\n\\nTypeError: can only concatenate str (not \"int\") to str\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.select_dtypes(include='number').mean())\n",
    "print(inputs)\n",
    "\n",
    "\"\"\"2-1-data-preparation.ipynb bug\n",
    "\n",
    "```python\n",
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)\n",
    "```\n",
    "https://github.com/d2l-ai/d2l-zh/pull/1331\n",
    "    由于旧版Pandas库在对inputs执行mean()方法时，会跳过不可计算的类型，从而忽略报错直接计算出数据；\n",
    "    而高版本pandas库会对数据类型进行严格检查，从而触发报错：\n",
    "    “TypeError: can only concatenate str (not \"int\") to str”\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "Cell In[4], line 2\n",
    "      1 inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "----> 2 inputs = inputs.fillna(inputs.mean())\n",
    "      3 print(inputs)\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\frame.py:11693, in DataFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n",
    "  11685 @doc(make_doc(\"mean\", ndim=2))\n",
    "  11686 def mean(\n",
    "  11687     self,\n",
    "   (...)\n",
    "  11691     **kwargs,\n",
    "  11692 ):\n",
    "> 11693     result = super().mean(axis, skipna, numeric_only, **kwargs)\n",
    "  11694     if isinstance(result, Series):\n",
    "  11695         result = result.__finalize__(self, method=\"mean\")\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\generic.py:12420, in NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n",
    "  12413 def mean(\n",
    "  12414     self,\n",
    "  12415     axis: Axis | None = 0,\n",
    "   (...)\n",
    "  12418     **kwargs,\n",
    "  12419 ) -> Series | float:\n",
    "> 12420     return self._stat_function(\n",
    "  12421         \"mean\", nanops.nanmean, axis, skipna, numeric_only, **kwargs\n",
    "  12422     )\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\generic.py:12377, in NDFrame._stat_function(self, name, func, axis, skipna, numeric_only, **kwargs)\n",
    "  12373 nv.validate_func(name, (), kwargs)\n",
    "  12375 validate_bool_kwarg(skipna, \"skipna\", none_allowed=False)\n",
    "> 12377 return self._reduce(\n",
    "  12378     func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only\n",
    "  12379 )\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\frame.py:11562, in DataFrame._reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\n",
    "  11558     df = df.T\n",
    "  11560 # After possibly _get_data and transposing, we are now in the\n",
    "  11561 #  simple case where we can use BlockManager.reduce\n",
    "> 11562 res = df._mgr.reduce(blk_func)\n",
    "  11563 out = df._constructor_from_mgr(res, axes=res.axes).iloc[0]\n",
    "  11564 if out_dtype is not None and out.dtype != \"boolean\":\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1500, in BlockManager.reduce(self, func)\n",
    "   1498 res_blocks: list[Block] = []\n",
    "   1499 for blk in self.blocks:\n",
    "-> 1500     nbs = blk.reduce(func)\n",
    "   1501     res_blocks.extend(nbs)\n",
    "   1503 index = Index([None])  # placeholder\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:404, in Block.reduce(self, func)\n",
    "    398 @final\n",
    "    399 def reduce(self, func) -> list[Block]:\n",
    "    400     # We will apply the function and reshape the result into a single-row\n",
    "    401     #  Block with the same mgr_locs; squeezing will be done at a higher level\n",
    "    402     assert self.ndim == 2\n",
    "--> 404     result = func(self.values)\n",
    "    406     if self.values.ndim == 1:\n",
    "    407         res_values = result\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\frame.py:11481, in DataFrame._reduce.<locals>.blk_func(values, axis)\n",
    "  11479         return np.array([result])\n",
    "  11480 else:\n",
    "> 11481     return op(values, axis=axis, skipna=skipna, **kwds)\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds)\n",
    "    145         result = alt(values, axis=axis, skipna=skipna, **kwds)\n",
    "    146 else:\n",
    "--> 147     result = alt(values, axis=axis, skipna=skipna, **kwds)\n",
    "    149 return result\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs)\n",
    "    401 if datetimelike and mask is None:\n",
    "    402     mask = isna(values)\n",
    "--> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\n",
    "    406 if datetimelike:\n",
    "    407     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\nanops.py:719, in nanmean(values, axis, skipna, mask)\n",
    "    716     dtype_count = dtype\n",
    "    718 count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n",
    "--> 719 the_sum = values.sum(axis, dtype=dtype_sum)\n",
    "    720 the_sum = _ensure_numeric(the_sum)\n",
    "    722 if axis is not None and getattr(the_sum, \"ndim\", False):\n",
    "\n",
    "File d:\\edison\\anaconda3\\envs\\test\\lib\\site-packages\\numpy\\core\\_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where)\n",
    "     47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
    "     48          initial=_NoValue, where=True):\n",
    "---> 49     return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
    "\n",
    "TypeError: can only concatenate str (not \"int\") to str\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于inputs中的类别值或离散值，我们将“NaN”视为一个类别。 由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”， pandas可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。 巷子类型为“Pave”的行会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0。 缺少巷子类型的行会将“Alley_Pave”和“Alley_nan”分别设置为0和1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0        True      False\n",
      "1       2.0       False       True\n",
      "2       4.0       False       True\n",
      "3       3.0       False       True\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3 转换为张量格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在inputs和outputs中的所有条目都是数值类型，它们可以转换为张量格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 3), dtype=float64, numpy=\n",
       " array([[3., 1., 0.],\n",
       "        [2., 0., 1.],\n",
       "        [4., 0., 1.],\n",
       "        [3., 0., 1.]])>,\n",
       " <tf.Tensor: shape=(4,), dtype=float64, numpy=array([127500., 106000., 178100., 140000.])>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = tf.constant(inputs.to_numpy(dtype=float))\n",
    "y = tf.constant(outputs.to_numpy(dtype=float))\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.4 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pandas软件包是Python中常用的数据分析工具中，pandas可以与张量兼容。\n",
    "* 用pandas处理缺失的数据时，我们可根据情况选择用插值法和删除法。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
